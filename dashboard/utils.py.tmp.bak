import json
import logging
import os
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, Optional, Union

from flask import Response, jsonify


def validate_config(config: dict[str, Any]) -> bool:
"""
Validate configuration structure and values.
Returns True if valid, False otherwise.
"""
required_fields = ["metrics", "websocket", "influxdb"]
try:
# Check required fields
for field in required_fields:
if field not in config:
logging.error(f"Missing required field: {field}")
return False
# Validate metrics configuration
metrics = config["metrics"]
if not isinstance(metrics.get("collection_interval"), (int, float)):
logging.error("Invalid collection interval")
return False
if not isinstance(metrics.get("enabled_metrics"), list):
logging.error("Invalid enabled metrics format")
return False
# Validate websocket configuration
websocket = config["websocket"]
if not isinstance(websocket.get("port"), int):
logging.error("Invalid websocket port")
return False
# Validate InfluxDB configuration
influxdb = config["influxdb"]
required_influxdb = ["url", "token", "org", "bucket"]
for field in required_influxdb:
if field not in influxdb:
logging.error(f"Missing required InfluxDB field: {field}")
return False
return True
except Exception as e:
logging.error(f"Configuration validation error: {e}")
return False
def format_bytes(size: float) -> str:
"""
Format byte size to human readable format.
Example: 1234567 -> "1.18 MB"
"""
try:
for unit in ["B", "KB", "MB", "GB", "TB"]:
if size < 1024.0:
return f"{size:.2f} {unit}"
size /= 1024.0
return f"{size:.2f} PB"
except Exception as e:
logging.error(f"Error formatting bytes: {e}")
return "0 B"
def parse_duration(duration: str) -> Optional[timedelta]:
"""
Parse duration string to timedelta.
Examples: "5m" -> 5 minutes, "1h" -> 1 hour
"""
try:
value = int(duration[:-1])
unit = duration[-1].lower()
if unit == "s":
return timedelta(seconds=value)
elif unit == "m":
return timedelta(minutes=value)
elif unit == "h":
return timedelta(hours=value)
elif unit == "d":
return timedelta(days=value)
else:
logging.error(f"Invalid duration unit: {unit}")
return None
except Exception as e:
logging.error(f"Error parsing duration: {e}")
return None
def sanitize_metric_name(name: str) -> str:
"""
Sanitize metric name for storage.
Removes special characters and spaces.
"""
try:
# Replace spaces and special characters with underscores
sanitized = re.sub(r"[^a-zA-Z0-9]", "_", name.lower())
# Remove consecutive underscores
sanitized = re.sub(r"_+", "_", sanitized)
# Remove leading/trailing underscores
return sanitized.strip("_")
except Exception as e:
logging.error(f"Error sanitizing metric name: {e}")
return "unknown_metric"
def load_config(path: str) -> dict[str, Any]:
"""
Load configuration from JSON file.
Returns configuration dictionary.
"""
try:
with open(path) as f:
config = json.load(f)
if not validate_config(config):
raise ValueError("Invalid configuration")
return config
except Exception as e:
logging.error(f"Error loading configuration: {e}")
raise
def setup_logging(level: str, log_file: str) -> None:
"""
Setup logging configuration.
Configures both file and console logging.
"""
try:
# Create log directory if it doesn't exist
log_dir = os.path.dirname(log_file)
os.makedirs(log_dir, exist_ok=True)
# Convert string level to logging level
numeric_level = getattr(logging, level.upper(), logging.INFO)
# Configure logging
logging.basicConfig(
level=numeric_level,
format="%(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)",
handlers=[logging.FileHandler(log_file), logging.StreamHandler()],
    )
except Exception as e:
logging.error(f"Error setting up logging: {e}")
raise
def create_response(
data: dict[str, Any],
status_code: int = 200,
headers: Optional[dict[str, str]] = None,
    ) -> Response:
"""
Create standardized JSON response.
Includes proper headers and status code.
"""
try:
response = jsonify(data)
response.status_code = status_code
if headers:
for key, value in headers.items():
response.headers[key] = value
return response
except Exception as e:
logging.error(f"Error creating response: {e}")
return jsonify({"error": str(e)}), 500
def parse_timestamp(timestamp: str) -> Optional[datetime]:
"""
Parse timestamp string to datetime.
Supports multiple formats.
"""
formats = [
"%Y-%m-%dT%H:%M:%S.%fZ",
"%Y-%m-%dT%H:%M:%SZ",
"%Y-%m-%d %H:%M:%S",
"%Y-%m-%d",
    ]
for fmt in formats:
try:
return datetime.strptime(timestamp, fmt)
except ValueError:
continue
logging.error(f"Unable to parse timestamp: {timestamp}")
return None
def validate_metrics(metrics: dict[str, Any]) -> bool:
"""
Validate metrics data structure.
Returns True if valid, False otherwise.
"""
try:
required_fields = ["cpu_percent", "memory_percent", "disk_percent", "timestamp"]
# Check required fields
for field in required_fields:
if field not in metrics:
logging.error(f"Missing required metric field: {field}")
return False
# Validate numeric fields
for field in ["cpu_percent", "memory_percent", "disk_percent"]:
value = metrics[field]
if not isinstance(value, (int, float)) or not 0 <= value <= 100:
logging.error(f"Invalid metric value for {field}: {value}")
return False
# Validate timestamp
if not parse_timestamp(metrics["timestamp"]):
logging.error(f"Invalid timestamp: {metrics['timestamp']}")
return False
return True
except Exception as e:
logging.error(f"Error validating metrics: {e}")
return False
